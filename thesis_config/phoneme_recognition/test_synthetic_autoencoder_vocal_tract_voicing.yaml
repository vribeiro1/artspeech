database_name: artspeech2
datadir: /srv/storage/talc2@talc-data2.nancy.grid5000.fr/multispeech/calcul/users/vsouzaribeiro/datasets/ArtSpeech2_Generated_Shapes/Autoencoder
batch_size: 4
num_workers: 5
vocab_filepath: /srv/storage/talc2@talc-data2.nancy.grid5000.fr/multispeech/calcul/users/vsouzaribeiro/datasets/ArtSpeech_Database_2/vocabulary.json
pretrained: false
feature: vocal_tract
loss: CTC
target: ctc_target
plot_target: articulatory_target
voicing_filepath: /home/vsouzaribeiro/workspace/artspeech/phoneme_recognition/config/voicing.json
state_dict_filepath: /srv/storage/talc2@talc-data2.nancy.grid5000.fr/multispeech/calcul/users/vsouzaribeiro/paper_files/thesis/mlruns/367275904485465921/6b0cd08309f34a59bdda32f1939afcc7/artifacts/best_model.pt
save_dir: /srv/storage/talc2@talc-data2.nancy.grid5000.fr/multispeech/calcul/users/vsouzaribeiro/paper_files/thesis/mlruns/367275904485465921/6b0cd08309f34a59bdda32f1939afcc7/artifacts/synthetic_autoencoder
model_params:
    in_channels: 2
    num_residual_layers: 4
    num_rnn_layers: 2
    rnn_hidden_size: 64
    num_features: 500
    adapter_out_features: 80
    dropout: 0.1
seq_dict:
    "1775": []
    "1777": []
    "1789": []
    "1791": []